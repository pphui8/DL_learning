{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "GoI83dDc39pn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare"
      ],
      "metadata": {
        "id": "w1Bbr3Qf31k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        datasets.CIFAR10(\n",
        "          root='./data',\n",
        "          train=True,\n",
        "          download=True,\n",
        "          transform=transforms.Compose([\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(\n",
        "                [0.5, 0.5, 0.5],  # RGB 平均\n",
        "                [0.5, 0.5, 0.5]   # RGB 標準偏差\n",
        "                )\n",
        "          ])),\n",
        "        batch_size=128,\n",
        "        shuffle=True\n",
        "    )\n",
        " \n",
        "test_loader = DataLoader(\n",
        "    datasets.CIFAR10(\n",
        "      root='./data',\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(\n",
        "              [0.5, 0.5, 0.5],  # RGB 平均\n",
        "              [0.5, 0.5, 0.5]  # RGB 標準偏差\n",
        "          )\n",
        "      ])),\n",
        "    batch_size=128,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "575acWfJ3482"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # CIFAR10のクラス\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "sample_datas, lables = next(dataiter)\n",
        "\n",
        "index = 3\n",
        "\n",
        "print( classes[lables[index]] )\n",
        "\n",
        "first_image = sample_datas[index]\n",
        "\n",
        "# convert the image tensor to a numpy array\n",
        "first_image = first_image.numpy()\n",
        "\n",
        "# transpose the image array to match the expected shape of matplotlib\n",
        "first_image = np.transpose(first_image, (1, 2, 0))\n",
        "\n",
        "# plot the image using pyplot\n",
        "plt.imshow(first_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "9nEck_F2IHso",
        "outputId": "de2cc0b5-7b87-43a6-f6a6-7828dd7c76c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plane\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model train"
      ],
      "metadata": {
        "id": "n0sgJyJ7Njus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvolutionalNeuralNetwork, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        3,    # input channel size\n",
        "        6,    # output channel size\n",
        "        5     # kernel size\n",
        "    )\n",
        "    self.pool = nn.MaxPool2d(\n",
        "        2,    # kernel size\n",
        "        2     # stride\n",
        "    )\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(\n",
        "        16 * 5 * 5,   # input size  (fixed)\n",
        "        120           # output size\n",
        "    )\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # -> n, 3, 32, 32\n",
        "    x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "    x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "    x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "    x = F.relu(self.fc1(x))               # -> n, 120\n",
        "    x = F.relu(self.fc2(x))               # -> n, 84\n",
        "    x = self.fc3(x)                       # -> n, 10\n",
        "    return x\n",
        "\n",
        "model = ConvolutionalNeuralNetwork().to(device)\n",
        "\n",
        "\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 5\n",
        "\n",
        "# loss\n",
        "criterion = nn.CrossEntropyLoss() # softmax\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# save\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# test\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4orQIIEH7Oat",
        "outputId": "7fc01a43-395c-45e3-fc69-303babc73926"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n",
            "Accuracy of the network: 10.34 %\n",
            "Accuracy of plane: 0.0 %\n",
            "Accuracy of car: 0.0 %\n",
            "Accuracy of bird: 0.0 %\n",
            "Accuracy of cat: 0.0 %\n",
            "Accuracy of deer: 0.0 %\n",
            "Accuracy of dog: 0.0 %\n",
            "Accuracy of frog: 0.0 %\n",
            "Accuracy of horse: 100.0 %\n",
            "Accuracy of ship: 9.375 %\n",
            "Accuracy of truck: 0.0 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}