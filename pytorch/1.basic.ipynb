{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P7sp-6zu-anz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### basic"
      ],
      "metadata": {
        "id": "rmDt-l16k-q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2, 2)\n",
        "y = torch.randn(2, 2)\n",
        "\n",
        "# same operation\n",
        "z = x + y\n",
        "z = torch.add(x, y)\n",
        "z = x.add_(y)\n",
        "\n",
        "# n-th colomns / rows\n",
        "x = torch.randn(5, 3)\n",
        "print(x[:, 0])  # first colomns\n",
        "print(x[0, :])  # frist row\n",
        "\n",
        "# difference between CPU and GPU\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "# CPU\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)  # a, b point to the same address\n",
        "\n",
        "# GPU\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)  # a, b point to the different address"
      ],
      "metadata": {
        "id": "FUT_5npU_7Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create a neuron"
      ],
      "metadata": {
        "id": "JJlS63iplF2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declear a tensor that will be used to do gradient operation\n",
        "x = torch.ones(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# create a neuron\n",
        "# cache will be automatically stored\n",
        "# backpropagation functino will be automatically generated\n",
        "y = x + 2\n",
        "print(y)  # contains a gradient function\n",
        "z = y * y * 2\n",
        "z = z.mean()  # Returns the mean value of all elements in the input tensor.\n",
        "print(z)\n",
        "\n",
        "z.backward()  # dz / dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "cqVjD-er-fW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### how to turn off gradient funciton"
      ],
      "metadata": {
        "id": "E2YYi-1TlKmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prevent track gradient\n",
        "x.requires_grad_(False)\n",
        "x.detach()\n",
        "with torch.no_grad():\n",
        "  y = x + 2\n",
        "  print(y)  # y has no gradient functino attribute"
      ],
      "metadata": {
        "id": "e293K2iFizaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### things to be careful"
      ],
      "metadata": {
        "id": "H7CAZ9VTlSwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# be careful when processing gradient\n",
        "# remember to reset the gradient\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights * 3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)   # wrong when the loop > 1\n",
        "\n",
        "  # weights.grad.zero_()  # set gradients to zero"
      ],
      "metadata": {
        "id": "YvNZHViDk78V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}