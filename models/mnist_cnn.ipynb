{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from torchvision import datasets, transforms,utils"
      ],
      "metadata": {
        "id": "mCJ7Gtf-GjtZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean=[0.5],std=[0.5])])\n",
        "\n",
        "train_data = datasets.MNIST(root = \"./data/\",\n",
        "                            transform=transform,\n",
        "                            train = True,\n",
        "                            download = True)\n",
        "\n",
        "test_data = datasets.MNIST(root=\"./data/\",\n",
        "                           transform = transform,\n",
        "                           train = False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=64,\n",
        "                                          shuffle=True,num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=64,\n",
        "                                          shuffle=True,num_workers=2)"
      ],
      "metadata": {
        "id": "pcC0FWLrGx0n"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)#两个池化，所以是7*7而不是14*14\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "#       self.dp = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        x = x.view(-1, 64 * 7* 7)#将数据平整为一维的 \n",
        "        x = F.relu(self.fc1(x))\n",
        "#       x = self.fc3(x)\n",
        "#       self.dp(x)\n",
        "        x = F.relu(self.fc2(x))   \n",
        "        x = self.fc3(x)  \n",
        "#       x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要\n",
        "        return x\n",
        "\n",
        "net = CNN()"
      ],
      "metadata": {
        "id": "UUaS8H2XHHYE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "#也可以选择Adam优化方法\n",
        "# optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)"
      ],
      "metadata": {
        "id": "cWbFcnrPHuj4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accs = []\n",
        "train_loss = []\n",
        "test_accs = []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = net.to(device)\n",
        "for epoch in range(3):\n",
        "    running_loss = 0.0\n",
        "    for i,data in enumerate(train_loader,0):#0是下标起始位置默认为0\n",
        "        # data 的格式[[inputs, labels]]       \n",
        "#         inputs,labels = data\n",
        "        inputs,labels = data[0].to(device), data[1].to(device)\n",
        "        #初始为0，清除上个batch的梯度信息\n",
        "        optimizer.zero_grad()         \n",
        "\n",
        "        #前向+后向+优化     \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss 的输出，每个一百个batch输出，平均的loss\n",
        "        running_loss += loss.item()\n",
        "        if i%100 == 99:\n",
        "            print('[%d,%5d] loss :%.3f' %\n",
        "                 (epoch+1,i+1,running_loss/100))\n",
        "            running_loss = 0.0\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        # 训练曲线的绘制 一个batch中的准确率\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total = labels.size(0)# labels 的长度\n",
        "        correct = (predicted == labels).sum().item() # 预测正确的数目\n",
        "        train_accs.append(100*correct/total)\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkjRd22zHx1K",
        "outputId": "13c51e55-484e-4cde-c85e-6d29da97b5ba"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  100] loss :2.293\n",
            "[1,  200] loss :2.267\n",
            "[1,  300] loss :2.213\n",
            "[1,  400] loss :2.061\n",
            "[1,  500] loss :1.544\n",
            "[1,  600] loss :0.870\n",
            "[1,  700] loss :0.567\n",
            "[1,  800] loss :0.439\n",
            "[1,  900] loss :0.386\n",
            "[2,  100] loss :0.332\n",
            "[2,  200] loss :0.314\n",
            "[2,  300] loss :0.289\n",
            "[2,  400] loss :0.260\n",
            "[2,  500] loss :0.240\n",
            "[2,  600] loss :0.228\n",
            "[2,  700] loss :0.228\n",
            "[2,  800] loss :0.211\n",
            "[2,  900] loss :0.185\n",
            "[3,  100] loss :0.176\n",
            "[3,  200] loss :0.153\n",
            "[3,  300] loss :0.174\n",
            "[3,  400] loss :0.161\n",
            "[3,  500] loss :0.139\n",
            "[3,  600] loss :0.137\n",
            "[3,  700] loss :0.132\n",
            "[3,  800] loss :0.145\n",
            "[3,  900] loss :0.126\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './mnist_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "OU0g5Q7_OEV-"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net = CNN()\n",
        "test_net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "def print_img(img):\n",
        "  grid = utils.make_grid(img)\n",
        "  grid = grid.numpy().transpose(1,2,0) \n",
        "  std = [0.5]\n",
        "  mean = [0.5]\n",
        "  grid = grid * std + mean\n",
        "  plt.imshow(grid)\n",
        "  plt.show()\n",
        "\n",
        "index = 9077\n",
        "with torch.no_grad():\n",
        "  img, label = train_data[index]\n",
        "  output = test_net(img)\n",
        "  _, predicted = torch.max(output, dim = 1)\n",
        "  print(\"the munber is: \", str(label))\n",
        "  print(\"predict is: \", predicted[0])\n",
        "  print_img(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "dT8iVvCwLvbF",
        "outputId": "4e47a421-20f5-48fd-d1eb-6b3a809863c3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the munber is:  7\n",
            "predict is:  tensor(7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = test_net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels)\n",
        "#         print(predicted == labels)\n",
        "        for i in range(10):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %d : %2d %%' % (\n",
        "        i, 100 * class_correct[i] / class_total[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0naS_NzFVH-u",
        "outputId": "7945993c-38ab-4081-dfef-66851bc2e9ed"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of 0 : 98 %\n",
            "Accuracy of 1 : 98 %\n",
            "Accuracy of 2 : 93 %\n",
            "Accuracy of 3 : 99 %\n",
            "Accuracy of 4 : 97 %\n",
            "Accuracy of 5 : 96 %\n",
            "Accuracy of 6 : 96 %\n",
            "Accuracy of 7 : 95 %\n",
            "Accuracy of 8 : 95 %\n",
            "Accuracy of 9 : 97 %\n"
          ]
        }
      ]
    }
  ]
}