{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RCNN for CIFAR-100"
      ],
      "metadata": {
        "id": "u71v0ad8B2T9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "6T5Yi112B5Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"resnet in pytorch\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.\n",
        "    Deep Residual Learning for Image Recognition\n",
        "    https://arxiv.org/abs/1512.03385v1\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
        "    \"\"\"\n",
        "\n",
        "    #BasicBlock and BottleNeck block\n",
        "    #have different output size\n",
        "    #we use class attribute expansion\n",
        "    #to distinct\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        #residual function\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "        )\n",
        "\n",
        "        #shortcut\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        #the shortcut output dimension is not the same with residual function\n",
        "        #use 1*1 convolution to match the dimension\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    \"\"\"Residual block for resnet over 50 layers\n",
        "    \"\"\"\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "        #we use a different inputsize than the original paper\n",
        "        #so conv2_x's stride is 1\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
        "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
        "        contain more than one residual block\n",
        "        Args:\n",
        "            block: block type, basic block or bottle neck block\n",
        "            out_channels: output depth channel number of this layer\n",
        "            num_blocks: how many blocks per layer\n",
        "            stride: the stride of the first block of this layer\n",
        "        Return:\n",
        "            return a resnet layer\n",
        "        \"\"\"\n",
        "\n",
        "        # we have num_block blocks per layer, the first block\n",
        "        # could be 1 or 2, other blocks would always be 1\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def resnet18():\n",
        "    \"\"\" return a ResNet 18 object\n",
        "    \"\"\"\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def resnet34():\n",
        "    \"\"\" return a ResNet 34 object\n",
        "    \"\"\"\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "def resnet50():\n",
        "    \"\"\" return a ResNet 50 object\n",
        "    \"\"\"\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
        "\n",
        "def resnet101():\n",
        "    \"\"\" return a ResNet 101 object\n",
        "    \"\"\"\n",
        "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
        "\n",
        "def resnet152():\n",
        "    \"\"\" return a ResNet 152 object\n",
        "    \"\"\"\n",
        "    return ResNet(BottleNeck, [3, 8, 36, 3])\n"
      ],
      "metadata": {
        "id": "UXhBWC0JKyfP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare data"
      ],
      "metadata": {
        "id": "yKE196E4CCro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### classes"
      ],
      "metadata": {
        "id": "BY_cG-EZCL5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "super_class_names = [\n",
        "  'aquatic mammals',  # 0：水生哺乳類\n",
        "  'fish',  # 1：魚\n",
        "  'flowers',  # ：花\n",
        "  'food containers',  # 3：食品容器\n",
        "  'fruit and vegetables',  # 4：果物と野菜\n",
        "  'household electrical devices',  # 5：家電\n",
        "  'household furniture',  # 6：家具\n",
        "  'insects',  # 7：昆虫\n",
        "  'large carnivores',  # 8：大型の肉食動物\n",
        "  'large man-made outdoor things',  # 9：大型の建造物\n",
        "  'large natural outdoor scenes',  # 10：大自然の風景\n",
        "  'large omnivores and herbivores',  # 11：大型の雑食動物と草食動物\n",
        "  'medium-sized mammals',  # 12：中型の哺乳類\n",
        "  'non-insect invertebrates',  # 13：昆虫ではない無脊椎動物\n",
        "  'people',  # 14：人\n",
        "  'reptiles',  # 15：爬虫類\n",
        "  'small mammals',  # 16：小型の哺乳類\n",
        "  'trees',  # 17：木\n",
        "  'vehicles 1',  # 18：車両1\n",
        "  'vehicles 2',  # 19：車両2\n",
        "]\n",
        "\n",
        "class_names = [\n",
        "  'apples',  # 0：りんご\n",
        "  'aquarium fish',  # 1：観賞魚\n",
        "  'baby',  # 2：赤ちゃん\n",
        "  'bear',  # 3：クマ\n",
        "  'beaver',  # 4：ビーバー\n",
        "  'bed',  # 5：ベッド\n",
        "  'bee',  # 6：蜂\n",
        "  'beetle',  # 7：カブトムシ\n",
        "  'bicycle',  # 8：自転車\n",
        "  'bottles',  # 9：ボトル\n",
        "  'bowls',  # 10：ボウル\n",
        "  'boy',  # 11：少年\n",
        "  'bridge',  # 12：橋\n",
        "  'bus',  # 13：バス\n",
        "  'butterfly',  # 14：蝶\n",
        "  'camel',  # 15：ラクダ\n",
        "  'cans',  # 16：缶\n",
        "  'castle',  # 17：城\n",
        "  'caterpillar',  # 18：毛虫\n",
        "  'cattle',  # 19：牛\n",
        "  'chair',  # 20：椅子\n",
        "  'chimpanzee',  # 21：チンパンジー\n",
        "  'clock',  # 22：時計\n",
        "  'cloud',  # 23：雲\n",
        "  'cockroach',  # 24：ゴキブリ\n",
        "  'couch',  # 25：ソファー\n",
        "  'crab',  # 26：カニ\n",
        "  'crocodile',  # 27：ワニ\n",
        "  'cups',  # 28：カップ\n",
        "  'dinosaur',  # 29：恐竜\n",
        "  'dolphin',  # 30：イルカ\n",
        "  'elephant',  # 31：象\n",
        "  'flatfish',  # 32：ヒラメ\n",
        "  'forest',  # 33：森\n",
        "  'fox',  # 34：キツネ\n",
        "  'girl',  # 35：少女\n",
        "  'hamster',  # 36：ハムスター\n",
        "  'house',  # 37：家\n",
        "  'kangaroo',  # 38：カンガルー\n",
        "  'computer keyboard',  # 39：コンピューターのキーボード\n",
        "  'lamp',  # 40：ランプ\n",
        "  'lawn-mower',  # 41：芝刈り機\n",
        "  'leopard',  # 42：ヒョウ\n",
        "  'lion',  # 43：ライオン\n",
        "  'lizard',  # 44：トカゲ\n",
        "  'lobster',  # 45：ロブスター\n",
        "  'man',  # 46：成人男性\n",
        "  'maple',  # 47：もみじ\n",
        "  'motorcycle',  # 48：オートバイ\n",
        "  'mountain',  # 49：山\n",
        "  'mouse',  # 50：ねずみ\n",
        "  'mushrooms',  # 51：きのこ\n",
        "  'oak',  # 52：オーク\n",
        "  'oranges',  # 53：オレンジ\n",
        "  'orchids',  # 54：蘭\n",
        "  'otter',  # 55：カワウソ\n",
        "  'palm',  # 56：ヤシ\n",
        "  'pears',  # 57：洋ナシ\n",
        "  'pickup truck',  # 58：ピックアップトラック\n",
        "  'pine',  # 59：松\n",
        "  'plain',  # 60：平野\n",
        "  'plates',  # 61：皿\n",
        "  'poppies',  # 62：ポピー\n",
        "  'porcupine',  # 63：ヤマアラシ\n",
        "  'possum',  # 64：フクロネズミ\n",
        "  'rabbit',  # 65：ウサギ\n",
        "  'raccoon',  # 66：アライグマ\n",
        "  'ray',  # 67：エイ\n",
        "  'road',  # 68：道路\n",
        "  'rocket',  # 69：ロケット\n",
        "  'roses',  # 70：バラ\n",
        "  'sea',  # 71：海\n",
        "  'seal',  # 72：アザラシ\n",
        "  'shark',  # 73：サメ\n",
        "  'shrew',  # 74：トガリネズミ\n",
        "  'skunk',  # 75：スカンク\n",
        "  'skyscraper',  # 76：超高層ビル\n",
        "  'snail',  # 77：カタツムリ\n",
        "  'snake',  # 78：ヘビ\n",
        "  'spider',  # 79：クモ\n",
        "  'squirrel',  # 80：リス\n",
        "  'streetcar',  # 81：路面電車\n",
        "  'sunflowers',  # 82：ひまわり\n",
        "  'sweet peppers',  # 83：パプリカ\n",
        "  'table',  # 84：テーブル\n",
        "  'tank',  # 85：タンク\n",
        "  'telephone',  # 86：電話\n",
        "  'television',  # 87：テレビ\n",
        "  'tiger',  # 88：トラ\n",
        "  'tractor',  # 89：トラクター\n",
        "  'train',  # 90：電車\n",
        "  'trout',  # 91：マス\n",
        "  'tulips',  # 92：チューリップ\n",
        "  'turtle',  # 93：カメ\n",
        "  'wardrobe',  # 94：ワードローブ\n",
        "  'whale',  # 95：クジラ\n",
        "  'willow',  # 96：柳\n",
        "  'wolf',  # 97：オオカミ\n",
        "  'woman',  # 98：成人女性\n",
        "  'worm',  # 99：ミミズ\n",
        "]"
      ],
      "metadata": {
        "id": "Pw_GKPHcCIHm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### datasets"
      ],
      "metadata": {
        "id": "fS1p54P5COHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        transform=transforms.ToTensor(),\n",
        "        download=True,\n",
        "    ),\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.CIFAR100(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        transform=transforms.ToTensor(),\n",
        "        download=True,\n",
        "    ),\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "model = resnet101()\n",
        "\n",
        "# show a example data\n",
        "index = 10\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "(img, label) = next(dataiter)\n",
        "\n",
        "print(img[0].shape)\n",
        "print(class_names[label[index].item()])\n",
        "plt.imshow(torch.rot90(img[index].T, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "2yXGi7AluHKb",
        "outputId": "6ac1ac45-d95f-416b-bf20-ebcb4af23b49"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "torch.Size([3, 32, 32])\n",
            "sea\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa4c27abb20>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define hyperparameter"
      ],
      "metadata": {
        "id": "QqS6n5LeGWU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.003\n",
        "num_epoch = 5\n",
        "momentum = 0.9\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=5e-4)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "      print('epoch: ', i, 'loss: ', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0oxnVmiGcOM",
        "outputId": "3ff794ac-6c86-4dae-f5de-5b36d91d8af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  4.865226745605469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "gImCMDTXMOdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "acc = 100.0 * n_correct / n_samples\n",
        "print('acc: ', acc)"
      ],
      "metadata": {
        "id": "-lmmAJGTMPTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6T5Yi112B5Rr",
        "BY_cG-EZCL5Q"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}