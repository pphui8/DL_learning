{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    return np.pad(X, ((0, 0),(pad, pad),(pad, pad),(0, 0)), 'constant', constant_values=0)\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    # Element-wise product between a_slice and W. Add bias.\n",
        "    s = np.multiply(a_slice_prev, W) + b\n",
        "    # Sum over all entries of the volume s\n",
        "    return np.sum(s)\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape (≈1 line)\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n",
        "    n_H = 1 + int((n_H_prev + 2 * pad - f) / stride)\n",
        "    n_W = 1 + int((n_W_prev + 2 * pad - f) / stride)\n",
        "    \n",
        "    # Initialize the output volume Z with zeros. (≈1 line)\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):                               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev_pad[i]                               # Select ith training example's padded activation\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                  \n",
        "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
        "                    Z[i, h, w, c] = np.sum(np.multiply(a_slice_prev, W[:, :, :, c]) + b[:, :, :, c])\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def conv_backward(dZ, cache):\n",
        "    # Retrieve information from \"cache\"\n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve dimensions from W's shape\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Retrieve dimensions from dZ's shape\n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    \n",
        "    # Initialize dA_prev, dW, db with the correct shapes\n",
        "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
        "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "    db = np.zeros((1, 1, 1, n_C))\n",
        "\n",
        "    # Pad A_prev and dA_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = A_prev_pad[i]\n",
        "        da_prev_pad = dA_prev_pad[i]\n",
        "        \n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "                    \n",
        "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "        dA_prev[i, :, :, :] = dA_prev_pad[i, pad:-pad, pad:-pad, :]\n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def create_mask_from_window(x):\n",
        "    return (x == np.max(x))\n",
        "\n",
        "def distribute_value(dz, shape):\n",
        "    \"\"\"\n",
        "    Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "    Arguments:\n",
        "    dz -- input scalar\n",
        "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "    Returns:\n",
        "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve dimensions from shape (≈1 line)\n",
        "    (n_H, n_W) = shape\n",
        "    \n",
        "    # Compute the value to distribute on the matrix (≈1 line)\n",
        "    average = dz / (n_H * n_W)\n",
        "    \n",
        "    # Create a matrix where every entry is the \"average\" value (≈1 line)  \n",
        "    return np.ones(shape) * average\n",
        "\n",
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the backward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
        "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Retrieve information from cache (≈1 line)\n",
        "    (A_prev, hparameters) = cache\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
        "    stride = hparameters['stride']\n",
        "    f = hparameters['f']\n",
        "    \n",
        "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    m, n_H, n_W, n_C = dA.shape\n",
        "    \n",
        "    # Initialize dA_prev with zeros (≈1 line)\n",
        "    dA_prev = np.zeros_like(A_prev)\n",
        "    \n",
        "    for i in range(m):                       # loop over the training examples\n",
        "        \n",
        "        # select training example from A_prev (≈1 line)\n",
        "        a_prev = A_prev[i]\n",
        "        for h in range(n_H):                   # loop on the vertical axis\n",
        "            for w in range(n_W):               # loop on the horizontal axis\n",
        "                for c in range(n_C):           # loop over the channels (depth)\n",
        "                    \n",
        "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Compute the backward propagation in both modes.\n",
        "                    if mode == \"max\":\n",
        "                        \n",
        "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        # Create the mask from a_prev_slice (≈1 line)\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += mask * dA[i, vert_start, horiz_start, c]\n",
        "                        \n",
        "                    elif mode == \"average\":\n",
        "                        # Get the value a from dA (≈1 line)\n",
        "                        da = dA[i, vert_start, horiz_start, c]\n",
        "                        # Define the shape of the filter as fxf (≈1 line)\n",
        "                        shape = (f, f)\n",
        "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "    \n",
        "    return dA_prev"
      ],
      "metadata": {
        "id": "u_ks0enMyPAy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow.python.framework import ops\n",
        "# import mnist\n",
        "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Y_train_orig = Y_train_orig.T\n",
        "# Y_test_orig = Y_test_orig.T\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)\n",
        "\n",
        "# Example of a picture\n",
        "index = 6\n",
        "plt.imshow(X_train_orig[index])\n",
        "print (\"y = \" + str(np.squeeze(Y_train_orig[index])))\n",
        "\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "Y_train = tf.one_hot(Y_train_orig, 6)\n",
        "# Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = tf.one_hot(Y_test_orig, 6)\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))\n",
        "conv_layers = {}"
      ],
      "metadata": {
        "id": "woXQi9XV9Vgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "fec86eb4-ee7d-431f-9af9-ead346842662"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 1\n",
            "number of training examples = 60000\n",
            "number of test examples = 10000\n",
            "X_train shape: (60000, 28, 28)\n",
            "Y_train shape: (60000, 6)\n",
            "X_test shape: (10000, 28, 28)\n",
            "Y_test shape: (10000, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_H0 -- scalar, height of an input image\n",
        "    n_W0 -- scalar, width of an input image\n",
        "    n_C0 -- scalar, number of channels of the input\n",
        "    n_y -- scalar, number of classes\n",
        "        \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (≈2 lines)\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_H0, n_W0, n_C0))\n",
        "    Y = tf.placeholder(tf.float32,shape=(None,n_y))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [4, 4, 3, 8]\n",
        "                        W2 : [2, 2, 8, 16]\n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, W2\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
        "        \n",
        "    ### START CODE HERE ### (approx. 2 lines of code)\n",
        "    W1 =tf.get_variable('W1',[4,4,3,8],initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
        "    W2 = tf.get_variable('W2',[2,2,8,16],initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
        "    ### END CODE HERE ###\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"W2\": W2}\n",
        "    \n",
        "    return parameters\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "\n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "\n",
        "    # CONV2D: stride of 1, padding 'SAME'\n",
        "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
        "    # RELU\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
        "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
        "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
        "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
        "    # RELU\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
        "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
        "    # FLATTEN\n",
        "    P2 = tf.contrib.layers.flatten(P2)\n",
        "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
        "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\"\n",
        "    Z3 = tf.contrib.layers.fully_connected(P2, num_outputs = 6, activation_fn=None)\n",
        "\n",
        "    return Z3\n",
        "\n",
        "\n",
        "def compute_cost(Z3, Y):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n",
        "    \n",
        "    return cost\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
        "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer ConvNet in Tensorflow:\n",
        "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (None, 64, 64, 3)\n",
        "    Y_train -- test set, of shape (None, n_y = 6)\n",
        "    X_test -- training set, of shape (None, 64, 64, 3)\n",
        "    Y_test -- test set, of shape (None, n_y = 6)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
        "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
        "    seed = 3                                          # to keep results consistent (numpy seed)\n",
        "    (m, n_H0, n_W0) = X_train.shape          \n",
        "    n_C0 = 1   \n",
        "    n_y = Y_train.shape[1]                            \n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of the correct shape\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables globally\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "       # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            minibatch_cost = 0.\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                minibatch_cost += temp_cost / num_minibatches\n",
        "                          # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
        "            if print_cost == True and epoch % 1 == 0:\n",
        "                costs.append(minibatch_cost)\n",
        "        \n",
        "        \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        predict_op = tf.argmax(Z3, 1)\n",
        "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
        "        \n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        print(accuracy)\n",
        "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
        "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
        "        print(\"Train Accuracy:\", train_accuracy)\n",
        "        print(\"Test Accuracy:\", test_accuracy)\n",
        "                \n",
        "        return train_accuracy, test_accuracy, parameters"
      ],
      "metadata": {
        "id": "pfVap1jP_XpI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "_EmwTD4DFGiz",
        "outputId": "2ede8e1e-f9ec-4865-9cef-29f6e37745a6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ddfc1f084c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-4b1d6b92da6a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Initialize parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m### START CODE HERE ### (1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-4b1d6b92da6a>\u001b[0m in \u001b[0;36minitialize_parameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m### START CODE HERE ### (approx. 2 lines of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v1' has no attribute 'contrib'"
          ]
        }
      ]
    }
  ]
}